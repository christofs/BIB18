[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "bib18",
    "section": "",
    "text": "Website containing analyses of the Bibliographie18 Dataset.\nFor more information on the dataset, see: https://github.com/christofs/bibliographie18."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Website containing analyses of the Bibliographie18 Dataset, by Christof Schöch."
  },
  {
    "objectID": "titles.html",
    "href": "titles.html",
    "title": "Titles",
    "section": "",
    "text": "The titles included in the bibliography tell us a few things, for instance the language a publication is written in or the main themes (keywords, authors) that is the subject of a publication. Let’s find out about them.\n\n\nCode\n# === Imports === \n\n# Basics\nimport re \nfrom os.path import realpath, dirname, join\nimport os\nfrom lxml import etree\nfrom collections import Counter\nimport pandas as pd\n\n# Visualization\nimport plotly.io as pio\npio.renderers.default = \"plotly_mimetype+notebook_connected\"\nimport plotly.express as px\n\n\n# === Files and parameters === \n\nwdir  = join(\"/\", \"media\", \"christof\", \"Data\", \"Github\", \"christofs\", \"bib18\")\n#bib18_file = join(wdir, \"data\", \"Bib18_test.rdf\") \nbib18_file = join(wdir, \"data\", \"Bib18.rdf\") \n\nnamespaces = {\n    \"foaf\" : \"http://xmlns.com/foaf/0.1/\",\n    \"bib\" : \"http://purl.org/net/biblio#\",\n    \"dc\" : \"http://purl.org/dc/elements/1.1/\",\n    \"z\" : \"http://www.zotero.org/namespaces/export#\",\n    \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\n    }"
  },
  {
    "objectID": "titles-OLD.html",
    "href": "titles-OLD.html",
    "title": "Titles",
    "section": "",
    "text": "The titles included in the bibliography tell us a few things, for instance the language a publication is written in or the main themes (keywords, authors) that is the subject of a publication. Let’s find out about them.\n\nimport plotly.io as pio\npio.renderers.default = \"plotly_mimetype+notebook_connected\"\n\n\"\"\"\nScript to analyse the languages of publications in the Bib18 dataset. \n\"\"\"\n\n# === Imports === \n\nimport re \nfrom os.path import realpath, dirname, join\nimport os\nfrom lxml import etree\nfrom collections import Counter\nimport pandas as pd\n\nimport plotly.express as px\n\n\n# === Files and parameters === \n\nwdir  = join(\"/\", \"media\", \"christof\", \"Data\", \"Github\", \"christofs\", \"bib18\", \"bib18\")\nbib18_file = join(wdir, \"data\", \"Bib18_test.rdf\") \n#bibdatafile = join(wdir, \"data\", \"Bib18.rdf\") \n\nnamespaces = {\n    \"foaf\" : \"http://xmlns.com/foaf/0.1/\",\n    \"bib\" : \"http://purl.org/net/biblio#\",\n    \"dc\" : \"http://purl.org/dc/elements/1.1/\",\n    \"z\" : \"http://www.zotero.org/namespaces/export#\",\n    \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\n    }\n\n\n# === Functions === \n\ndef read_json(bib18_file): \n    \"\"\"\n    Open and read the RDF version of the Bib18 dataset.\n    Returns: the XML document as an etree object. \n    \"\"\"\n    bib18 = etree.parse(bib18_file)\n    return bib18\n\n\n\ndef get_titles(bib18): \n    \"\"\"\n    Extract all the primary titles from the dataset. \n    Primary titles are all titles except journal names. \n    \"\"\"\n    # Find all primary \"title\" elements in the dataset \n    # TODO: find the XPath to exclude journal titles. \n    xpath = \"//dc:title/text()\"\n    titles = bib18.xpath(xpath, namespaces=namespaces)\n    print(\"Number of titles found: \" + str(len(titles)) + \".\")\n    return titles\n\n\n\ndef identify_language(title): \n    from lingua import Language, LanguageDetectorBuilder\n    languages = [Language.ENGLISH,\n                 Language.FRENCH,\n                 Language.GERMAN,\n                 Language.SPANISH,\n                 Language.ITALIAN,\n                 Language.PORTUGUESE,\n                 Language.DUTCH,\n                 Language.SWEDISH,\n                 Language.NYNORSK,\n                 Language.BOKMAL,\n                 Language.DANISH,\n                 Language.FINNISH,\n                 ]\n    detector = LanguageDetectorBuilder.from_languages(*languages).build()\n    confidence_values = detector.compute_language_confidence_values(title)\n    languages = [language for language, value in confidence_values]\n    values = [value for language, value in confidence_values]\n    confidence_values_dict = dict(zip(languages, values))\n    max_language = max(confidence_values_dict, key=confidence_values_dict.get)\n    lang = max_language.name.title()\n    return lang\n\n\ndef get_titles_langs_counts(titles): \n    \"\"\"\n    For each title, collect the language identified by py-lingua. \n    Returns: DataFrame (names and counts of all languages in all titles)\n    \"\"\"\n    titles_langs = []\n    for title in titles: \n        titles_langs.append(identify_language(title))\n    titles_langs_counts = dict(Counter(titles_langs))\n    #tlc_df = pd.DataFrame.from_dict(titles_langs_counts, orient=\"index\").reset_index()#.rename(mapper={\"index\":\"year\", 0 : \"count\"}, axis=\"columns\")   \n    #print(tlc_df.head())\n\n\n\ndef visualize_titles_langs_counts(titles_langs_counts): \n    \"\"\"\n    Create a barplot of the languages in the datset.\n    Returns: Nothing, but outputs a plot / saves a file. \n    \"\"\"\n    print(\"nothing\")\n\n\n\n\n\n# === Main === \n\ndef main(): \n    bib18 = read_json(bib18_file)\n    titles = get_titles(bib18)\n    titles_langs_counts = get_titles_langs_counts(titles)\nmain()\n\nNumber of titles found: 149."
  },
  {
    "objectID": "titles.html#introduction",
    "href": "titles.html#introduction",
    "title": "Titles",
    "section": "",
    "text": "The titles included in the bibliography tell us a few things, for instance the language a publication is written in or the main themes (keywords, authors) that is the subject of a publication. Let’s find out about them.\n\n\nCode\n# === Imports === \n\n# Basics\nimport re \nfrom os.path import realpath, dirname, join\nimport os\nfrom lxml import etree\nfrom collections import Counter\nimport pandas as pd\n\n# Visualization\nimport plotly.io as pio\npio.renderers.default = \"plotly_mimetype+notebook_connected\"\nimport plotly.express as px\n\n\n# === Files and parameters === \n\nwdir  = join(\"/\", \"media\", \"christof\", \"Data\", \"Github\", \"christofs\", \"bib18\")\n#bib18_file = join(wdir, \"data\", \"Bib18_test.rdf\") \nbib18_file = join(wdir, \"data\", \"Bib18.rdf\") \n\nnamespaces = {\n    \"foaf\" : \"http://xmlns.com/foaf/0.1/\",\n    \"bib\" : \"http://purl.org/net/biblio#\",\n    \"dc\" : \"http://purl.org/dc/elements/1.1/\",\n    \"z\" : \"http://www.zotero.org/namespaces/export#\",\n    \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\n    }"
  },
  {
    "objectID": "titles.html#extracting-the-titles",
    "href": "titles.html#extracting-the-titles",
    "title": "Titles",
    "section": "Extracting the titles",
    "text": "Extracting the titles\nThe first step is to identify the titles in the dataset. Ideally, we would exclude titles of journals, for instance, but this is not done here yet.\n\n\nCode\ndef read_json(bib18_file): \n    \"\"\"\n    Open and read the RDF version of the Bib18 dataset.\n    Returns: the XML document as an etree object. \n    \"\"\"\n    bib18 = etree.parse(bib18_file)\n    return bib18\n\n\ndef get_titles(bib18): \n    \"\"\"\n    Extract all the primary titles from the dataset. \n    Primary titles are all titles except journal names. \n    \"\"\"\n    # Find all primary \"title\" elements in the dataset \n    # TODO: find the XPath to exclude journal titles. \n    xpath = \"//dc:title/text()\"\n    titles = bib18.xpath(xpath, namespaces=namespaces)\n    print(\"Number of titles found: \" + str(len(titles)) + \".\")\n    return titles\n\n# === Main === \n\ndef main(): \n    # Make variable global (=&gt; accessible to next cells)\n    global titles \n    bib18 = read_json(bib18_file)\n    titles = get_titles(bib18)\nmain()\n\n\nNumber of titles found: 110174."
  },
  {
    "objectID": "titles.html#distribution-of-languages-based-on-the-titles",
    "href": "titles.html#distribution-of-languages-based-on-the-titles",
    "title": "Titles",
    "section": "Distribution of languages, based on the titles",
    "text": "Distribution of languages, based on the titles\nWe don’t have abstracts or full texts in the dataset, but on the basis of the titles alone, we can determine the (most likely) language of the publication.\n\n\nCode\ndef identify_language(title): \n    \"\"\"\n    For one title, detect the most likely language. \n    This function is called by \"get_titles_langs_counts()\". \n    Returns: str (language)\n    \"\"\"\n    from lingua import Language, LanguageDetectorBuilder\n    languages = [Language.ENGLISH,\n                 Language.FRENCH,\n                 Language.GERMAN,\n                 Language.SPANISH,\n                 Language.ITALIAN,\n                 Language.PORTUGUESE,\n                 Language.DUTCH,\n                 Language.SWEDISH,\n                 Language.NYNORSK,\n                 Language.BOKMAL,\n                 Language.DANISH,\n                 Language.FINNISH,\n                 ]\n    detector = LanguageDetectorBuilder.from_languages(*languages).build()\n    confidence_values = detector.compute_language_confidence_values(title)\n    languages = [language for language, value in confidence_values]\n    values = [value for language, value in confidence_values]\n    confidence_values_dict = dict(zip(languages, values))\n    max_language = max(confidence_values_dict, key=confidence_values_dict.get)\n    lang = max_language.name.title()\n    return lang\n\n\ndef get_titles_langs_counts(titles): \n    \"\"\"\n    For each title, collect the language identified by py-lingua. \n    Returns: DataFrame (names and counts of all languages in all titles)\n    \"\"\"\n    titles_langs = []\n    for title in titles: \n        titles_langs.append(identify_language(title))\n    titles_langs_counts = dict(Counter(titles_langs))\n    tlc = pd.DataFrame.from_dict(titles_langs_counts, orient=\"index\").reset_index().rename(mapper={\"index\":\"language\", 0 : \"count\"}, axis=\"columns\")\n    tlc.sort_values(by=\"count\", ascending=False, inplace=True)\n    print(\"The following table shows the number of times the top 10 languages occur in the dataset.\\n\")\n    # TODO: Make this a prettier table.\n    print(tlc.head(10))\n    return tlc\n\n\ndef main(titles): \n   global tlc\n   tlc = get_titles_langs_counts(titles) \nmain(titles)\n\n\nThe following table shows the number of times the top 10 languages occur in the dataset.\n\n      language  count\n0       French  79632\n1      English  21687\n3      Spanish   2039\n2      Italian   1995\n6       German   1597\n5      Swedish   1378\n7   Portuguese    624\n4        Dutch    394\n8      Nynorsk    301\n11     Finnish    185\n\n\nLet’s visualize this as well.\n\n\nCode\ndef visualize_tlc(tlc): \n    \"\"\"\n    Create a visualization (barplot) of the languages counts. \n    \"\"\"\n    fig = px.bar(\n        tlc, \n        x=\"language\", \n        y=\"count\", \n        title=\"Distribution of languages in the titles\")\n    fig.show()\n\n\ndef main(tlc): \n    visualize_tlc(tlc)\nmain(tlc)\n\n\n\n                                                \n\n\nThe dominance of French is very clear."
  },
  {
    "objectID": "titles.html#testing-interactiveness",
    "href": "titles.html#testing-interactiveness",
    "title": "Titles",
    "section": "Testing interactiveness",
    "text": "Testing interactiveness\n\n\nCode\nfrom dash import Dash, dcc, html, Input, Output\nimport plotly.express as px\n\napp = Dash(__name__)\n\napp.layout = html.Div([\n    html.H4('Analysis of Iris data using scatter matrix'),\n    dcc.Dropdown(\n        id=\"dropdown\",\n        options=['sepal_length', 'sepal_width', 'petal_length', 'petal_width'],\n        value=['sepal_length', 'sepal_width'],\n        multi=True\n    ),\n    dcc.Graph(id=\"graph\"),\n])\n\n\n@app.callback(\n    Output(\"graph\", \"figure\"), \n    Input(\"dropdown\", \"value\"))\ndef update_bar_chart(dims):\n    df = px.data.iris() # replace with your own data source\n    fig = px.scatter_matrix(\n        df, dimensions=dims, color=\"species\")\n    return fig"
  }
]