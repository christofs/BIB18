[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "bib18",
    "section": "",
    "text": "Website containing analyses of the Bibliographie18 Dataset.\nFor more information on the dataset, see: https://github.com/christofs/bibliographie18."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Website containing analyses of the Bibliographie18 Dataset, by Christof Schöch."
  },
  {
    "objectID": "titles.html",
    "href": "titles.html",
    "title": "Titles",
    "section": "",
    "text": "The titles included in the bibliography tell us a few things, for instance the language a publication is written in or the main themes (keywords, authors) that is the subject of a publication. Let’s find out about them. (The code below initializes the analyis.)\n\n\nCode\n# === Imports === \n\n# Basics\nimport re \nfrom os.path import realpath, dirname, join\nimport os\nfrom lxml import etree\nfrom collections import Counter\nimport pandas as pd\n\n# Visualization\nimport plotly.io as pio\npio.renderers.default = \"plotly_mimetype+notebook_connected\"\nimport plotly.express as px\n\n\n# === Files and parameters === \n\nwdir  = join(\"/\", \"media\", \"christof\", \"Data\", \"Github\", \"christofs\", \"bib18\")\n#Bib18_file = join(wdir, \"data\", \"Bib18_test.rdf\") \nBib18_file = join(wdir, \"data\", \"Bib18.rdf\") \n\nnamespaces = {\n    \"foaf\" : \"http://xmlns.com/foaf/0.1/\",\n    \"bib\" : \"http://purl.org/net/biblio#\",\n    \"dc\" : \"http://purl.org/dc/elements/1.1/\",\n    \"z\" : \"http://www.zotero.org/namespaces/export#\",\n    \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\n    }"
  },
  {
    "objectID": "titles.html#introduction",
    "href": "titles.html#introduction",
    "title": "Titles",
    "section": "",
    "text": "The titles included in the bibliography tell us a few things, for instance the language a publication is written in or the main themes (keywords, authors) that is the subject of a publication. Let’s find out about them. (The code below initializes the analyis.)\n\n\nCode\n# === Imports === \n\n# Basics\nimport re \nfrom os.path import realpath, dirname, join\nimport os\nfrom lxml import etree\nfrom collections import Counter\nimport pandas as pd\n\n# Visualization\nimport plotly.io as pio\npio.renderers.default = \"plotly_mimetype+notebook_connected\"\nimport plotly.express as px\n\n\n# === Files and parameters === \n\nwdir  = join(\"/\", \"media\", \"christof\", \"Data\", \"Github\", \"christofs\", \"bib18\")\n#Bib18_file = join(wdir, \"data\", \"Bib18_test.rdf\") \nBib18_file = join(wdir, \"data\", \"Bib18.rdf\") \n\nnamespaces = {\n    \"foaf\" : \"http://xmlns.com/foaf/0.1/\",\n    \"bib\" : \"http://purl.org/net/biblio#\",\n    \"dc\" : \"http://purl.org/dc/elements/1.1/\",\n    \"z\" : \"http://www.zotero.org/namespaces/export#\",\n    \"rdf\" : \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\n    }"
  },
  {
    "objectID": "titles.html#extracting-the-titles",
    "href": "titles.html#extracting-the-titles",
    "title": "Titles",
    "section": "Extracting the titles",
    "text": "Extracting the titles\nThe first step is to identify the titles in the dataset. Ideally, we would exclude titles of journals, for instance, but this is not done here yet.\n\n\nCode\ndef read_json(Bib18_file): \n    \"\"\"\n    Open and read the RDF version of the Bib18 dataset.\n    Returns: the XML document as an etree object. \n    \"\"\"\n    Bib18 = etree.parse(Bib18_file)\n    return Bib18\n\n\ndef get_titles(Bib18): \n    \"\"\"\n    Extract all the primary titles from the dataset. \n    Primary titles are all titles except journal names. \n    \"\"\"\n    # Find all primary \"title\" elements in the dataset \n    # TODO: find the XPath to exclude journal titles. \n    xpath = \"//dc:title/text()\"\n    titles = Bib18.xpath(xpath, namespaces=namespaces)\n    print(\"Number of titles found: \" + str(len(titles)) + \".\")\n    return titles\n\n# === Main === \n\ndef main(): \n    global Bib18   \n    Bib18 = read_json(Bib18_file)\n    global titles \n    titles = get_titles(Bib18)\nmain()\n\n\nNumber of titles found: 110174."
  },
  {
    "objectID": "titles.html#distribution-of-languages-based-on-the-titles",
    "href": "titles.html#distribution-of-languages-based-on-the-titles",
    "title": "Titles",
    "section": "Distribution of languages, based on the titles",
    "text": "Distribution of languages, based on the titles\nWe don’t have abstracts or full texts in the dataset, but on the basis of the titles alone, the (most likely) language of the publication can be determined. (Note that an algorithmic process, based on the library py-lingua and using only the sometimes very short titles, has been used to create this data, so errors are to be expected. With the progress of corrections in the dataset, this will improve over time.)\nThe following table shows the number of times several different languages occur in the dataset.\n\n\nCode\ndef get_lang_counts(Bib18): \n    \"\"\"\n    Extract all the language elements from the dataset. \n    Then, establish the counts of the languages. \n    \"\"\"\n    # Find all \"language\" elements in the dataset. \n    xpath = \"//z:language/text()\"\n    langs = Bib18.xpath(xpath, namespaces=namespaces)\n    print(\"Number of language indications found: \" + str(len(langs)) + \".\")\n\n    # Establish the counts of each language\n    lang_counts = dict(Counter(langs))\n    lang_counts = pd.DataFrame.from_dict(lang_counts, orient=\"index\").reset_index().rename(mapper={\"index\":\"language\", 0 : \"count\"}, axis=\"columns\")\n    lang_counts.sort_values(by=\"count\", ascending=False, inplace=True)\n\n    # Display the table nicely\n    display(lang_counts.head(10).style.hide(axis=\"index\"))\n\n    # Save the data to a CSV file (as runtime is long)\n    with open(join(wdir, \"data\", \"lang_counts.csv\"), \"w\", encoding=\"utf8\") as outfile: \n        lang_counts.to_csv(outfile)\n\n    # Return data\n    return lang_counts\n\nglobal lang_counts\nlang_counts = get_lang_counts(Bib18)\n\n\nNumber of language indications found: 64396.\n\n\n\n\n\n\n\nlanguage\ncount\n\n\n\n\nFrench\n47579\n\n\nEnglish\n13348\n\n\nItalian\n958\n\n\nGerman\n915\n\n\nSpanish\n866\n\n\nDutch\n282\n\n\nSwedish\n231\n\n\nPortuguese\n217\n\n\n\n\n\nLet’s visualize this data as well.\n\n\nCode\ndef visualize_tlc(lang_counts): \n    \"\"\"\n    Create a visualization (barplot) of the languages counts. \n    \"\"\"\n    fig = px.bar(\n        lang_counts.head(10), \n        x=\"language\", \n        y=\"count\", \n        title=\"Distribution of languages in the titles\",\n        text_auto=True)\n    fig.show(renderer=\"notebook\")\n\nvisualize_tlc(lang_counts)\n\n\n\n                                                \n\n\nThe dominance of French is very clear, followed by English. As noted above, this analysis will be strongly improved with manual corrections to the language information."
  }
]